{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What about the LLMs?\n",
    "\n",
    "**You must write the answer to this question in a notebook hosted in your github account and give access to your supervisor.**\n",
    "\n",
    "LLMs are reputed to have revolutionised automatic language processing. Since the introduction of BERT-type models, all language processing applications have been based on LLMs, of varying degrees of sophistication and size. These models are trained on multiple tasks and are therefore capable of performing new tasks without learning, simply from a prompt. This is known as \"zero-shot learning\" because there is no learning phase as such. We are going to test these models on our classification task.\n",
    "\n",
    "Huggingface is a Franco-American company that develops tools for building applications based on Deep Learning. In particular, it hosts the huggingface.co portal, which contains numerous Deep Learning models. These models can be used very easily thanks to the [Transformer] library (https://huggingface.co/docs/transformers/quicktour) developed by HuggingFace.\n",
    "\n",
    "Using a transform model in zero-shot learning with HuggingFace is very simple: [see documentation](https://huggingface.co/tasks/zero-shot-classification)\n",
    "\n",
    "However, you need to choose a suitable model from the list of models compatible with Zero-Shot classification. HuggingFace offers [numerous models](https://huggingface.co/models?pipeline_tag=zero-shot-classification). \n",
    "\n",
    "The classes proposed to the model must also provide sufficient semantic information for the model to understand them.\n",
    "\n",
    "**Question**:\n",
    "\n",
    "* Write a code to classify an example of text from an article in Le Monde using a model transformed using zero-sot learning with the HuggingFace library.\n",
    "* choose a model and explain your choice\n",
    "* choose a formulation for the classes to be predicted\n",
    "* show that the model predicts a class for the text of the article (correct or incorrect, analyse the results)\n",
    "* evaluate the performance of your model on 100 articles (a test set).\n",
    "* note model sizes, processing times and classification results\n",
    "\n",
    "\n",
    "Notes :\n",
    "* make sure that you use the correct Tokenizer when using a model \n",
    "* start testing with a small number of articles and the first 100's of characters for faster experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "import time\n",
    "\n",
    "# Load the dataset\n",
    "csv_file_path = 'data/LeMonde2003_9classes.csv.gz'\n",
    "df = pd.read_csv(csv_file_path, compression='gzip')\n",
    "\n",
    "# Remove the class 'UNE' and merge 'FRANCE' and 'SOCIETE'\n",
    "df = df[df['category'] != 'UNE']\n",
    "df.loc[df['category'] == 'FRA', 'category'] = 'SOC'\n",
    "\n",
    "# Create new splits\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Extract features and labels for the test set\n",
    "X_test = test_df['text']\n",
    "y_test = test_df['category']\n",
    "\n",
    "# Choose a model for zero-shot classification\n",
    "model_name = \"MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "classifier = pipeline(\"zero-shot-classification\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle ``MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7`` trouvé sur HF est un modèle de Zero-Shot classification pour le texte et compatible avec le français. C'est le meilleur que j'ai trouvé après en avoir testé quelque uns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the candidate labels and their mappings in French with more expressive descriptions\n",
    "candidate_labels = [\n",
    "    \"article sur les entreprises et le monde des affaires\",\n",
    "    \"article sur l'actualité internationale\",\n",
    "    \"article sur les arts et la culture\",\n",
    "    \"article sur la société française et les questions sociales\",\n",
    "    \"article sur le sport\"\n",
    "]\n",
    "label_mapping = {\n",
    "    \"article sur les entreprises et le monde des affaires\": \"ENT\",\n",
    "    \"article sur l'actualité internationale\": \"INT\",\n",
    "    \"article sur les arts et la culture\": \"ART\",\n",
    "    \"article sur la société française et les questions sociales\": \"SOC\",\n",
    "    \"article sur le sport\": \"SPO\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce type de label très explicite a plutôt bien fonctionné après quelques tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Result for Example Text:\n",
      "{'sequence': 'premier tirage 5 6 13 18 36 41 complémentaire 44 pas de gagnant pour 6 numéros gagnant pour 5 numéros et complémentaire 21 658,30 5 numéros 901,20 4 numéros et complémentaire 38 4 numéros 19 3 numéros et complémentaire 8,20 3 numéros 4,10 second tirage 4 17 18 21 30 44 complémentaire 41 rapports pour 6 numéros 912 567 5 numéros et complémentaire 17 486,70 5 numéros 911,50 4 numéros et complémentaire 41,80 4 numéros 20,90 3 numéros et complémentaire 4,60 3 numéros 2,30', 'labels': ['article sur le sport', 'article sur la société française et les questions sociales', 'article sur les entreprises et le monde des affaires', 'article sur les arts et la culture', \"article sur l'actualité internationale\"], 'scores': [0.9180249571800232, 0.03507557511329651, 0.022624339908361435, 0.01783699356019497, 0.0064380900003015995]}\n"
     ]
    }
   ],
   "source": [
    "# Classify an example text\n",
    "example_text = X_test.iloc[0]\n",
    "result = classifier(example_text, candidate_labels)\n",
    "print(\"Classification Result for Example Text:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Par exemple pour le texte : premier tirage 5 6 13 18 36 41 complémentaire 44 pas de gagnant pour 6 numéros gagnant pour 5 numéro\n",
      " Le modèle prédit label suivant : article sur le sport\n"
     ]
    }
   ],
   "source": [
    "print(f\"Par exemple pour le texte : {example_text[:100]}\\n\",\n",
    "      f\"Le modèle prédit label suivant : {result['labels'][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7000\n",
      "Average Processing Time: 0.3333 seconds\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "correct_predictions = 0\n",
    "total_articles = 100\n",
    "processing_times = []\n",
    "\n",
    "for i in range(total_articles):\n",
    "    text = X_test.iloc[i]\n",
    "    true_label = y_test.iloc[i]\n",
    "\n",
    "    start_time = time.time()\n",
    "    result = classifier(text, candidate_labels)\n",
    "    end_time = time.time()\n",
    "\n",
    "    predicted_label = label_mapping[result['labels'][0]]\n",
    "    processing_times.append(end_time - start_time)\n",
    "\n",
    "    if predicted_label == true_label:\n",
    "        correct_predictions += 1\n",
    "\n",
    "accuracy = correct_predictions / total_articles\n",
    "average_processing_time = sum(processing_times) / total_articles\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Average Processing Time: {average_processing_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Size: 278.81 million parameters\n"
     ]
    }
   ],
   "source": [
    "# Note model sizes and processing times\n",
    "model_size = sum(p.numel() for p in model.parameters()) / 1e6  # Model size in millions of parameters\n",
    "print(f\"Model Size: {model_size:.2f} million parameters\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
